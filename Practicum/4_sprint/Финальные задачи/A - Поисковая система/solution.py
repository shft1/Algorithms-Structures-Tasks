"""
ID посылки - https://contest.yandex.ru/contest/24414/run-report/140294363/

--- Принцип работы ---
Задача: Построить алгоритм поиска, который по заданному запросу выдает 5 самых релевантных документов.

Предварительная работа:
Для того, чтобы обеспечить быстрый поиск документов, предварительно создаются 2 вспомогательные хеш-структуры:
- doc_info – информация об имеющихся словах и их кол-ве в каждом документе.
    данная хеш-таблица позволяет моментально определять кол-во вхождений конкретного слова из запроса для данного документа
- search_idx – это поисковой индекс, который отображает каждое слово на документы, в которых это слово встречается.
    данный поисковой индекс избавляет нас от необходимости проверять каждый документ на наличие слова из запроса,
    а конкретно направляет на нужные документы, где будет производиться подсчет.

Алгоритм ранжирования документов для запроса:
1. Берется слово из запроса.
2. Если этого слова нет в поисковом индексе - переходим в Шаг 1.
3. Для каждого из документов, в котором это слово встречается, мы обращаемся к его информации о кол-ве слова из запроса.
4. Для каждого документа собираем сумму о кол-ве слов из запроса, которые в нем встречаются.
5. После подсчета всех слов из запроса, мы сортируем, в нужном нам порядке, документы и отбираем первые 5 из них.

--- Доказательства корректности ---
Доказательство полноты релевантных документов:
Каждый документ и слово в нем обрабывается последовательно.
Поэтому подсчет слов и их кол-ва в каждом документе работает корректно, и мы ничего не пропускаем.
По той же причине мы не пропускаем документы, которые содержат данное слово, возможные дубликаты документов,
при наличии одинаковых слов в нем, исключаются из выборки благодрая множеству, который не хранит повторы.
Исходя из этого описания следует, что алгоритм корректен (ЧТД :ъ)

--- Временная сложность ---
Cложность предварительной работы:
Для создания doc_info и search_idx нам нужно пройти по каждому слову каждого документа и
вычислить его хеш, обычно вычисление хеша линейно зависит от длины слова, следовательно:
--->>> Cложность предварительной работы - O(L), где L - суммарная длина всех слов во всех документах
Создание поискового индекса и информации о документах - это предварительная работа, которая выполняется единожды.
При каждом новом запросе-поиске пересчитывать их не нужно. Поэтому их временную сложность мы не будем учитывать в итоговой сложности алгоритма.

Cложность алгоритма складывается из сложностей нескольких частей:
1. Проход по каждому уникальному слову из каждого запроса и вычисление их хеша
- O(K), где K - суммарная длина всех уникальных слов каждого запроса
2. Вычисление номера корзины по полученному хешу для данного ключа:
- O(1 + a), где a - коэффициент заполнения хеш-таблицы
3. Проход по каждому документу для каждого слова каждого запроса:
- O(D), где D - суммарное кол-во поисковых документов для слов запроса
4. Ранжирование результата поиска для каждого запроса:
- O(MlogM), где M - суммарное кол-во релевантных документов

Итоговая временна сложность без расчета предварительной работы:
--->>> O(K + (1 + a) + D + MlogM)
Итоговая временна сложность с расчетом предварительной работы:
--->>> O(L + K + (1 + a) + D + MlogM)

--- Пространственная сложность ---
Cложность предварительной работы:
1. Хранение информации о словах и их кол-ве для каждого документа (doc_info):
- O(U), где U - суммарное кол-во уникальных слов в каждом документе
2. Хранение поискового индекса для слов документов
- O(W), где W - суммарное кол-во всех поисковых документов
Cложность предварительной работы:
--->>> O(U + W)
Хранение поискового индекса и информации о документах - это предварительная работа, которая выполняется единожды.
При каждом новом запросе-поиске происходит только обращение к ним.
Поэтому их пространственную сложность мы не будем учитывать в итоговой сложности.

Алгоритм использует память для хранения промежуточных и итоговых результатов, по поскольку эта часть
не относится к самому алгоритму и является необязательной мы не будем учитывать это, следовательно:

Итоговая пространственная сложность без учета предварительной работы:
--->>> O(1)
Итоговая пространственная сложность с учетом предварительной работы:
--->>> O(U + W)
"""

import sys


def create_index(n):
    doc_info, search_idx = {}, {}
    for i in range(1, n + 1):
        doc_info[i] = {}
        for word in sys.stdin.readline().rstrip().split():
            doc_info[i][word] = doc_info[i].get(word, 0) + 1
            doc_set = search_idx.get(word, set())
            doc_set.add(i)
            search_idx[word] = doc_set
    return doc_info, search_idx


def solution(di, si, m):
    res = []
    for _ in range(m):
        query = set(sys.stdin.readline().rstrip().split())
        res_q = {}
        for word in query:
            word_doc = si.get(word, [])
            for doc in word_doc:
                res_q[doc] = res_q.get(doc, 0) + di[doc][word]
        res.append(sorted(res_q.keys(), key=lambda x: (-res_q[x], x))[:5])
    return res


def main():
    n = int(sys.stdin.readline().rstrip())
    di, si = create_index(n)
    m = int(sys.stdin.readline().rstrip())
    res = solution(di, si, m)
    for sub_res in res:
        sys.stdout.write(" ".join(map(str, sub_res)) + "\n")


if __name__ == "__main__":
    main()
